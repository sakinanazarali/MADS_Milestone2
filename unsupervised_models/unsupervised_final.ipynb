{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37b6d58",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0748ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all relevant libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, make_scorer\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from rapidfuzz import process, fuzz\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157b98a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 80% missing data: ['label', 'ent_road', 'ent_house_number', 'ent_unit', 'ent_level', 'union', 'lab_entity', 'lab_house_number', 'lab_road', 'lab_city', 'lab_state', 'lab_postcode', 'lab_unit', 'lab_level', 'lab_phone_number']\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.read_csv(\"nlrb_current_final_6-20.csv\")\n",
    "\n",
    "# find all columns with more than 80% missing data\n",
    "missing_threshold = 0.8\n",
    "columns_with_missing_data = main_df.columns[main_df.isnull().mean() > missing_threshold]\n",
    "\n",
    "print(f\"Columns with more than 80% missing data: {list(columns_with_missing_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ec90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8 \n",
    "\n",
    "# drop columns with more than 80% of missing data in the col\n",
    "main_df = main_df.loc[:, main_df.isnull().mean() <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3517ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [\n",
    "            'entity',\n",
    "            'ent_city',\n",
    "            'ent_state',\n",
    "            'ent_postcode',\n",
    "            'ent_phone_number',\n",
    "            'charge_city',\n",
    "            'charge_state',\n",
    "            'region',\n",
    "            'region_city',\n",
    "            'region_state',\n",
    "            'case_name',\n",
    "            'case_number',\n",
    "            'role']\n",
    "\n",
    "# create a list of columns that are in the df but not in the specified new order\n",
    "reordered_columns = new_order + [col for col in main_df.columns if col not in new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e31db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply order\n",
    "main_df = main_df[reordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1b772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>ent_city</th>\n",
       "      <th>ent_state</th>\n",
       "      <th>ent_postcode</th>\n",
       "      <th>ent_phone_number</th>\n",
       "      <th>charge_city</th>\n",
       "      <th>charge_state</th>\n",
       "      <th>region</th>\n",
       "      <th>region_city</th>\n",
       "      <th>region_state</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_number</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pacific weather</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>98362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"pacific weather \"</td>\n",
       "      <td>03-ca-027869</td>\n",
       "      <td>cdp_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clp resources</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"clp resources and controlled environmental st...</td>\n",
       "      <td>03-ca-122609</td>\n",
       "      <td>cdp_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>98115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"graham construction &amp; management \"</td>\n",
       "      <td>03-ca-143167</td>\n",
       "      <td>cdp_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"true blue  f/k/a labor ready  and its wholly ...</td>\n",
       "      <td>04-ca-075160</td>\n",
       "      <td>cdp_re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcfarland cascade pole and lumber company</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"mcfarland cascade pole and lumber company \"</td>\n",
       "      <td>04-rc-067350</td>\n",
       "      <td>e_e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       entity      ent_city ent_state  \\\n",
       "0                             pacific weather  port angeles        wa   \n",
       "1                              clp resources         tacoma        wa   \n",
       "2            graham construction  management        seattle        wa   \n",
       "3                   ongaro burtt  louderback         tacoma        wa   \n",
       "4  mcfarland cascade pole and lumber company         tacoma        wa   \n",
       "\n",
       "  ent_postcode ent_phone_number   charge_city charge_state  region  \\\n",
       "0        98362              NaN  port angeles           wa       3   \n",
       "1        98402              NaN        tacoma           wa       3   \n",
       "2        98115              NaN       seattle           wa       3   \n",
       "3        98402              NaN        tacoma           wa       4   \n",
       "4        98421              NaN        tacoma           wa       4   \n",
       "\n",
       "    region_city  region_state  \\\n",
       "0       buffalo      new york   \n",
       "1       buffalo      new york   \n",
       "2       buffalo      new york   \n",
       "3  philadelphia  pennsylvania   \n",
       "4  philadelphia  pennsylvania   \n",
       "\n",
       "                                           case_name   case_number    role  \n",
       "0                                 \"pacific weather \"  03-ca-027869  cdp_re  \n",
       "1  \"clp resources and controlled environmental st...  03-ca-122609  cdp_re  \n",
       "2                \"graham construction & management \"  03-ca-143167  cdp_re  \n",
       "3  \"true blue  f/k/a labor ready  and its wholly ...  04-ca-075160  cdp_re  \n",
       "4       \"mcfarland cascade pole and lumber company \"  04-rc-067350     e_e  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['ent_phone_number'] = main_df['ent_phone_number'].astype(str)\n",
    "\n",
    "# clean and convert phone numbers to numeric\n",
    "main_df['ent_phone_number'] = main_df['ent_phone_number'].str.replace(r'[^\\d]', '', regex=True).astype(str)\n",
    "main_df['ent_phone_number'] = pd.to_numeric(main_df['ent_phone_number'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de73df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert relevant columns to numeric\n",
    "numeric_columns = ['ent_postcode', 'ent_phone_number']\n",
    "for col in numeric_columns:\n",
    "    main_df[col] = pd.to_numeric(main_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2805acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numeric columns to integers\n",
    "integer_columns = ['ent_postcode','ent_phone_number']\n",
    "main_df[integer_columns] = main_df[integer_columns].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546bfee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical columns\n",
    "categorical_columns = [\n",
    "    'charge_city', 'charge_state', 'region_city', 'region_state', 'ent_city', 'ent_state','role']\n",
    "\n",
    "# fill nan values for categorical columns with empty strings\n",
    "main_df[categorical_columns] = main_df[categorical_columns].fillna('')\n",
    "\n",
    "# convert categorical columns to string\n",
    "main_df[categorical_columns] = main_df[categorical_columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9fcfed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity              object\n",
      "ent_city            object\n",
      "ent_state           object\n",
      "ent_postcode         Int64\n",
      "ent_phone_number     Int64\n",
      "charge_city         object\n",
      "charge_state        object\n",
      "region               int64\n",
      "region_city         object\n",
      "region_state        object\n",
      "case_name           object\n",
      "case_number         object\n",
      "role                object\n",
      "dtype: object\n",
      "Column entity contains string values\n",
      "Column ent_city contains string values\n",
      "Column ent_state contains string values\n",
      "Column charge_city contains string values\n",
      "Column charge_state contains string values\n",
      "Column region_city contains string values\n",
      "Column region_state contains string values\n",
      "Column case_name contains string values\n",
      "Column case_number contains string values\n",
      "Column role contains string values\n"
     ]
    }
   ],
   "source": [
    "# check data types of all columns in main_df\n",
    "print(main_df.dtypes)\n",
    "\n",
    "# find all columns with mixed types or unexpected values\n",
    "for col in main_df.columns:\n",
    "    if main_df[col].apply(lambda x: isinstance(x, str)).any():\n",
    "        print(f\"Column {col} contains string values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bf33a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity              object\n",
      "ent_city            object\n",
      "ent_state           object\n",
      "ent_postcode         Int64\n",
      "ent_phone_number     Int64\n",
      "charge_city         object\n",
      "charge_state        object\n",
      "region               int64\n",
      "region_city         object\n",
      "region_state        object\n",
      "case_name           object\n",
      "case_number         object\n",
      "role                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# list of columns that should be strings\n",
    "string_columns = [\n",
    "    'entity', 'ent_city', 'ent_state', 'charge_city', 'charge_state',\n",
    "    'region_city', 'region_state', 'case_name', 'role']\n",
    "\n",
    "# convert specified columns to string type\n",
    "for col in string_columns:\n",
    "    main_df[col] = main_df[col].astype(str)\n",
    "\n",
    "# verify the conversion\n",
    "print(main_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0647ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill or drop nan values and ensure data consistency\n",
    "\n",
    "main_df.fillna({\n",
    "    'entity': '',\n",
    "    'ent_city': '',\n",
    "    'ent_state': '',\n",
    "    'ent_postcode': 0,\n",
    "    'ent_phone_number': 0,\n",
    "    'charge_city': '',\n",
    "    'charge_state': '',\n",
    "    'region': 0,\n",
    "    'region_city': '',\n",
    "    'region_state': '',\n",
    "    'case_name': '',\n",
    "    'case_number': '',\n",
    "    'role': ''\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6c7da",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ed0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size after tfidf: 3915\n"
     ]
    }
   ],
   "source": [
    "# isolate tfidf to see if it works on text cols (this was created because initially we were getting an error making\n",
    "# the tfidf fit into the text col and it would get rid of all of the \n",
    "# \"ValueError: empty vocabulary; perhaps the documents only contain stop words\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "try:\n",
    "    vectorized_text = vectorizer.fit_transform(main_df['case_name'])\n",
    "    print(\"vocab size after tfidf:\", len(vectorizer.vocabulary_))\n",
    "except ValueError:\n",
    "    print(\"empty vocab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038f6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functon to find the number of components using PCA that preserve 90% of variance. this will be used as input\n",
    "# in models that use PCA\n",
    "\n",
    "def find_optimal_components(df, text_columns, numeric_columns, categorical_columns, max_features):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df[text_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "    # one hot encoding categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "    # combine all the features\n",
    "    processed_features = pd.concat([pd.DataFrame(text_features.toarray()), pd.DataFrame(numeric_features), pd.DataFrame(categorical_features.toarray())], axis=1)\n",
    "\n",
    "    # apply PCA for dimensionality redction with 90% explained variance\n",
    "    pca = PCA(n_components=None)  # Set n_components to None initially\n",
    "    pca.fit(processed_features)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "                                                                                                                            \n",
    "    # find the number of components that explains 90% variance\n",
    "    num_components_90 = np.where(np.cumsum(explained_variance) >= 0.9)[0][0] + 1\n",
    "  \n",
    "    return num_components_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e92192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of components that preserve 90% of the variance \n",
    "\n",
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region'] # standardscaler for numerical columns\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']# one hot encoder for categorical columns\n",
    "text_columns = ['case_name']  # tf-idf vectorizer for text column\n",
    "max_features = 1000\n",
    "\n",
    "pca_n_components = find_optimal_components(main_df, text_columns, numeric_columns, categorical_columns, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd16c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008e7b3",
   "metadata": {},
   "source": [
    "pca_n_components = 164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6adadeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(df, text_columns, numeric_columns, categorical_columns, n_clusters_range, max_features, n_components):\n",
    "    \"\"\"\n",
    "    find optimal number of clusters using PCA\n",
    "\n",
    "    \"\"\"\n",
    "    # vectorize using tfidf\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df[text_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "    # one hot encoding categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "    # combine all the features\n",
    "    processed_features = pd.concat([pd.DataFrame(text_features.toarray()), pd.DataFrame(numeric_features), pd.DataFrame(categorical_features.toarray())], axis=1)\n",
    "\n",
    "    # apply PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_features = pca.fit_transform(processed_features)\n",
    "\n",
    "    # find optimal clusters using silhoutette method\n",
    "    sil_scores = []\n",
    "    for k in n_clusters_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(pca_features)\n",
    "        labels = kmeans.labels_\n",
    "        sil_scores.append(silhouette_score(pca_features, labels))\n",
    "\n",
    "    # find optimal clusters using davies-bouldin index\n",
    "    db_scores = []\n",
    "    for k in n_clusters_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(pca_features)\n",
    "        labels = kmeans.labels_\n",
    "        db_scores.append(davies_bouldin_score(pca_features, labels))\n",
    "\n",
    "    # find optimal clusters using calinski-harabasz index\n",
    "    ch_scores = []\n",
    "    for k in n_clusters_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(pca_features)\n",
    "        labels = kmeans.labels_\n",
    "        ch_scores.append(calinski_harabasz_score(pca_features, labels))\n",
    "\n",
    "    # find optimal clusters using avg within sum of square method (elbow method) (AWSS)\n",
    "    awss_values = []\n",
    "    for k in n_clusters_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(pca_features)\n",
    "        awss_values.append(kmeans.inertia_)\n",
    "\n",
    "    # plot elbow method\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_clusters_range, awss_values, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('AWSS')\n",
    "    plt.title('Elbow Method with AWSS')\n",
    "    plt.xticks(n_clusters_range)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # list optimum num of clusters based on different methods\n",
    "    optimal_n_clusters_silhouette = n_clusters_range[np.argmax(sil_scores)]\n",
    "    optimal_n_clusters_gap = visualizer.elbow_value_\n",
    "    optimal_n_clusters_davies_bouldin = n_clusters_range[np.argmin(db_scores)]\n",
    "    optimal_n_clusters_calinski_harabasz = n_clusters_range[np.argmax(ch_scores)]\n",
    "    optimal_n_clusters_awss = n_clusters_range[np.argmin(awss_values)]\n",
    "\n",
    "    return {\n",
    "        \"silhouette method\": optimal_n_clusters_silhouette,\n",
    "        \"gap stat\": optimal_n_clusters_gap,\n",
    "        \"davies bouldin index\": optimal_n_clusters_davies_bouldin,\n",
    "        \"calinski harabasz Index\": optimal_n_clusters_calinski_harabasz,\n",
    "        \"AWSS elbow method\": optimal_n_clusters_awss\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4de6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region']\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']\n",
    "text_columns = ['case_name']  \n",
    "n_clusters_range = range(10, 1000)\n",
    "max_features = 1000\n",
    "n_components = pca_n_components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41cb3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN - IT TAKES TOO LONG TO FIND THE CORRECT NUMBER OF CLUSTERS\n",
    "\n",
    "# find_optimal_clusters(main_df, text_columns, numeric_columns, categorical_columns, n_clusters_range, max_features, n_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882cf8b",
   "metadata": {},
   "source": [
    "Given that the aboce does not work, we can use fuzzywuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "029d0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of unique entities: 3926\n"
     ]
    }
   ],
   "source": [
    "entities = main_df['entity'].tolist()\n",
    "\n",
    "# function to find number of unique entity names by clustering entities spelt similarly\n",
    "def cluster_entities(entities, threshold):\n",
    "    unique_entities = []\n",
    "    for entity in entities:\n",
    "        match = process.extractOne(entity, unique_entities, scorer=fuzz.token_sort_ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            continue\n",
    "        unique_entities.append(entity)\n",
    "    return unique_entities\n",
    "\n",
    "# cluster entities and find unique entity names\n",
    "unique_entities = cluster_entities(entities, threshold=90)\n",
    "\n",
    "print(f\"num of unique entities: {len(unique_entities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bd7d5",
   "metadata": {},
   "source": [
    "## pca_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c585b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_pca_kmeans(df, text_columns, numeric_columns, categorical_columns, target_column, n_clusters, max_features, n_components, threshold=90):\n",
    "    \"\"\"\n",
    "    Standardize names in the target column using PCA and KMeans clustering.\n",
    "    \"\"\"\n",
    "    # make a copy of df not to edit main df\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # vectorize using tfidf\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df_copy[text_columns].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df_copy[numeric_columns])\n",
    "\n",
    "    # apply one-hot encoding for categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df_copy[categorical_columns])\n",
    "\n",
    "    # combine all features\n",
    "    processed_features = pd.concat([pd.DataFrame(text_features.toarray()), pd.DataFrame(numeric_features), pd.DataFrame(categorical_features.toarray())], axis=1)\n",
    "\n",
    "    # apply pca for dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_features = pca.fit_transform(processed_features)\n",
    "\n",
    "    # use k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(pca_features)\n",
    "\n",
    "    # assign the cluster labels to the data\n",
    "    df_copy['cluster'] = clusters\n",
    "\n",
    "    # find the most common name in each cluster and add it to the standardized_names dict\n",
    "    standardized_names = {}\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_data = df_copy[df_copy['cluster'] == cluster_id][target_column]\n",
    "        most_common_name = cluster_data.mode().iloc[0] if not cluster_data.mode().empty else \"Unknown\"\n",
    "        standardized_names[cluster_id] = most_common_name\n",
    "\n",
    "    # standardize name for each of the entities using the most common name detected\n",
    "    df_copy['standardized_name'] = df_copy['cluster'].map(standardized_names)\n",
    "\n",
    "    # evaluate clustering using diff metrics\n",
    "    silhouette_avg = silhouette_score(pca_features, clusters)\n",
    "    db_index = davies_bouldin_score(pca_features, clusters)\n",
    "    ch_index = calinski_harabasz_score(pca_features, clusters)\n",
    "\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "    print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "    print(f\"Calinski-Harabasz Index: {ch_index}\")\n",
    "\n",
    "    # evaluate similarity to see if the standardized name col is within 90% of similarity of the entity col \n",
    "    df_copy['similarity_score'] = df_copy.apply(lambda row: fuzz.token_sort_ratio(row[target_column], row['standardized_name']), axis=1)\n",
    "    matches = df_copy[df_copy['similarity_score'] >= threshold]\n",
    "    match_count = matches.shape[0]\n",
    "    pct_of_similarity = match_count / len(df_copy)\n",
    "\n",
    "    print(f\"Percentage of Similarity: {pct_of_similarity}\")\n",
    "\n",
    "    return df_copy, silhouette_avg, db_index, ch_index, pct_of_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a878a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.5723492859588513\n",
      "Davies-Bouldin Index: 0.5982182251751493\n",
      "Calinski-Harabasz Index: 486.97404638068906\n",
      "Percentage of Similarity: 0.5647598739106249\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region']\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']\n",
    "text_columns = ['case_name']  \n",
    "target_column = 'entity'\n",
    "n_clusters = len(unique_entities)\n",
    "max_features = 1000\n",
    "n_components = pca_n_components \n",
    "\n",
    "\n",
    "pca_kmeans_df, pca_kmeans_silhouette, pca_kmeans_db_index, pca_kmeans_ch_index, pca_kmeans_pca_similarity = unsupervised_pca_kmeans(main_df, text_columns, numeric_columns, categorical_columns, target_column, n_clusters, max_features, n_components, threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb228929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>ent_city</th>\n",
       "      <th>ent_state</th>\n",
       "      <th>ent_postcode</th>\n",
       "      <th>ent_phone_number</th>\n",
       "      <th>charge_city</th>\n",
       "      <th>charge_state</th>\n",
       "      <th>region</th>\n",
       "      <th>region_city</th>\n",
       "      <th>region_state</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_number</th>\n",
       "      <th>role</th>\n",
       "      <th>cluster</th>\n",
       "      <th>standardized_name</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pacific weather</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>98362</td>\n",
       "      <td>0</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"pacific weather \"</td>\n",
       "      <td>03-ca-027869</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>1527</td>\n",
       "      <td>pacific weather</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clp resources</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"clp resources and controlled environmental st...</td>\n",
       "      <td>03-ca-122609</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>1253</td>\n",
       "      <td>clp resources</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>98115</td>\n",
       "      <td>0</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"graham construction &amp; management \"</td>\n",
       "      <td>03-ca-143167</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>5</td>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"true blue  f/k/a labor ready  and its wholly ...</td>\n",
       "      <td>04-ca-075160</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>1656</td>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcfarland cascade pole and lumber company</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98421</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"mcfarland cascade pole and lumber company \"</td>\n",
       "      <td>04-rc-067350</td>\n",
       "      <td>e_e</td>\n",
       "      <td>272</td>\n",
       "      <td>mcfarland cascade holdings  a wholly owned sub...</td>\n",
       "      <td>51.239669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21567</th>\n",
       "      <td>oregon school employees association local 6732</td>\n",
       "      <td>milwaukie</td>\n",
       "      <td>or</td>\n",
       "      <td>97267</td>\n",
       "      <td>0</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>1493</td>\n",
       "      <td>oregon school employees association aft local</td>\n",
       "      <td>92.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>653</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21569</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>653</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21570</th>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>wa</td>\n",
       "      <td>98661</td>\n",
       "      <td>3606935841</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>1095</td>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>petermann northwest</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>98604</td>\n",
       "      <td>3606871479</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>e_e</td>\n",
       "      <td>3828</td>\n",
       "      <td>falck</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21572 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               entity       ent_city  \\\n",
       "0                                     pacific weather   port angeles   \n",
       "1                                      clp resources          tacoma   \n",
       "2                    graham construction  management         seattle   \n",
       "3                           ongaro burtt  louderback          tacoma   \n",
       "4          mcfarland cascade pole and lumber company          tacoma   \n",
       "...                                               ...            ...   \n",
       "21567  oregon school employees association local 6732      milwaukie   \n",
       "21568                                  first student     lake oswego   \n",
       "21569                                  first student     lake oswego   \n",
       "21570                              teamsters local 58      vancouver   \n",
       "21571                            petermann northwest   battle ground   \n",
       "\n",
       "      ent_state  ent_postcode  ent_phone_number    charge_city charge_state  \\\n",
       "0            wa         98362                 0   port angeles           wa   \n",
       "1            wa         98402                 0         tacoma           wa   \n",
       "2            wa         98115                 0        seattle           wa   \n",
       "3            wa         98402                 0         tacoma           wa   \n",
       "4            wa         98421                 0         tacoma           wa   \n",
       "...         ...           ...               ...            ...          ...   \n",
       "21567        or         97267                 0    lake oswego           or   \n",
       "21568        or         97035        5035342332    lake oswego           or   \n",
       "21569        or         97035        5035342332    lake oswego           or   \n",
       "21570        wa         98661        3606935841  battle ground           wa   \n",
       "21571        wa         98604        3606871479  battle ground           wa   \n",
       "\n",
       "       region   region_city  region_state  \\\n",
       "0           3       buffalo      new york   \n",
       "1           3       buffalo      new york   \n",
       "2           3       buffalo      new york   \n",
       "3           4  philadelphia  pennsylvania   \n",
       "4           4  philadelphia  pennsylvania   \n",
       "...       ...           ...           ...   \n",
       "21567      19       seattle    washington   \n",
       "21568      19       seattle    washington   \n",
       "21569      19       seattle    washington   \n",
       "21570      19       seattle    washington   \n",
       "21571      19       seattle    washington   \n",
       "\n",
       "                                               case_name   case_number  \\\n",
       "0                                     \"pacific weather \"  03-ca-027869   \n",
       "1      \"clp resources and controlled environmental st...  03-ca-122609   \n",
       "2                    \"graham construction & management \"  03-ca-143167   \n",
       "3      \"true blue  f/k/a labor ready  and its wholly ...  04-ca-075160   \n",
       "4           \"mcfarland cascade pole and lumber company \"  04-rc-067350   \n",
       "...                                                  ...           ...   \n",
       "21567                                   \"first student \"  36-ud-000376   \n",
       "21568                                   \"first student \"  36-ud-000376   \n",
       "21569                                   \"first student \"  36-ud-000376   \n",
       "21570                             \"petermann northwest \"  36-ud-000377   \n",
       "21571                             \"petermann northwest \"  36-ud-000377   \n",
       "\n",
       "         role  cluster                                  standardized_name  \\\n",
       "0      cdp_re     1527                                    pacific weather   \n",
       "1      cdp_re     1253                                     clp resources    \n",
       "2      cdp_re        5                   graham construction  management    \n",
       "3      cdp_re     1656                          ongaro burtt  louderback    \n",
       "4         e_e      272  mcfarland cascade holdings  a wholly owned sub...   \n",
       "...       ...      ...                                                ...   \n",
       "21567    ip_u     1493      oregon school employees association aft local   \n",
       "21568     e_e      653                                     first student    \n",
       "21569     e_e      653                                     first student    \n",
       "21570    ip_u     1095                                 teamsters local 58   \n",
       "21571     e_e     3828                                              falck   \n",
       "\n",
       "       similarity_score  \n",
       "0            100.000000  \n",
       "1            100.000000  \n",
       "2            100.000000  \n",
       "3            100.000000  \n",
       "4             51.239669  \n",
       "...                 ...  \n",
       "21567         92.307692  \n",
       "21568        100.000000  \n",
       "21569        100.000000  \n",
       "21570        100.000000  \n",
       "21571          8.333333  \n",
       "\n",
       "[21572 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_kmeans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b43e0",
   "metadata": {},
   "source": [
    "## pca_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6436ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_pca_agglomerative(df, text_columns, numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold, threshold=90):\n",
    "    \"\"\"\n",
    "    Standardize names in the target column using PCA and Agglomerative clustering.\n",
    "    \"\"\"\n",
    "    # make a copy of df not to lose\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # vectorize text columns using tfidf\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df_copy[text_columns].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df_copy[numeric_columns])\n",
    "\n",
    "    # apply one hot encoding for categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df_copy[categorical_columns])\n",
    "\n",
    "    # combine all features\n",
    "    processed_features = np.hstack([text_features.toarray(), numeric_features, categorical_features.toarray()])\n",
    "\n",
    "    # apply pca for dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_features = pca.fit_transform(processed_features)\n",
    "\n",
    "    # use agglomerative clustering with distance_threshold\n",
    "    agglomerative = AgglomerativeClustering(distance_threshold=distance_threshold, n_clusters=None)\n",
    "    clusters = agglomerative.fit_predict(pca_features)\n",
    "\n",
    "    # assign the cluster labels to the data\n",
    "    df_copy['cluster'] = clusters\n",
    "\n",
    "    # find the most common name in each cluster and add it to the standardized_names dict\n",
    "    standardized_names = {}\n",
    "    unique_clusters = df_copy['cluster'].unique()\n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_data = df_copy[df_copy['cluster'] == cluster_id][target_column]\n",
    "        most_common_name = cluster_data.mode().iloc[0] if not cluster_data.mode().empty else \"Unknown\"\n",
    "        standardized_names[cluster_id] = most_common_name\n",
    "\n",
    "    # standardize name for each of the entities using the most common name detected\n",
    "    df_copy['standardized_name'] = df_copy['cluster'].map(standardized_names)\n",
    "\n",
    "    # evaluate using different metrics\n",
    "    silhouette_avg = silhouette_score(pca_features, clusters)\n",
    "    db_index = davies_bouldin_score(pca_features, clusters)\n",
    "    ch_index = calinski_harabasz_score(pca_features, clusters)\n",
    "\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "    print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "    print(f\"Calinski-Harabasz Index: {ch_index}\")\n",
    "\n",
    "    # evaluate similarity to see if the standardized name col is within 90% of similarity of the entity col \n",
    "    df_copy['similarity_score'] = df_copy.apply(lambda row: fuzz.token_sort_ratio(row[target_column], row['standardized_name']), axis=1)\n",
    "    matches = df_copy[df_copy['similarity_score'] >= threshold]\n",
    "    match_count = matches.shape[0]\n",
    "    pct_of_similarity = match_count / len(df_copy)\n",
    "\n",
    "    print(f\"Percentage of similarity: {pct_of_similarity}\")\n",
    "\n",
    "    return df_copy, silhouette_avg, db_index, ch_index, pct_of_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9bb6342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6453628185406257\n",
      "Davies-Bouldin Index: 0.06677569657450089\n",
      "Calinski-Harabasz Index: 99935.2216992327\n",
      "Percentage of similarity: 0.8349249026515854\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region']\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']\n",
    "text_columns = ['case_name']  \n",
    "target_column = 'entity'\n",
    "max_features = 1000\n",
    "n_components = pca_n_components \n",
    "distance_threshold = 0.1\n",
    "\n",
    "\n",
    "pca_agg_df, pca_agg_silhouette, pca_agg_db_index, pca_agg_ch_index, pca_agg_similarity = unsupervised_pca_agglomerative(main_df, text_columns, numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold=distance_threshold, threshold=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f787d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>ent_city</th>\n",
       "      <th>ent_state</th>\n",
       "      <th>ent_postcode</th>\n",
       "      <th>ent_phone_number</th>\n",
       "      <th>charge_city</th>\n",
       "      <th>charge_state</th>\n",
       "      <th>region</th>\n",
       "      <th>region_city</th>\n",
       "      <th>region_state</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_number</th>\n",
       "      <th>role</th>\n",
       "      <th>cluster</th>\n",
       "      <th>standardized_name</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pacific weather</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>98362</td>\n",
       "      <td>0</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"pacific weather \"</td>\n",
       "      <td>03-ca-027869</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>6911</td>\n",
       "      <td>pacific weather</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clp resources</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"clp resources and controlled environmental st...</td>\n",
       "      <td>03-ca-122609</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>5751</td>\n",
       "      <td>clp resources</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>98115</td>\n",
       "      <td>0</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"graham construction &amp; management \"</td>\n",
       "      <td>03-ca-143167</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>6627</td>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"true blue  f/k/a labor ready  and its wholly ...</td>\n",
       "      <td>04-ca-075160</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>9523</td>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcfarland cascade pole and lumber company</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98421</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"mcfarland cascade pole and lumber company \"</td>\n",
       "      <td>04-rc-067350</td>\n",
       "      <td>e_e</td>\n",
       "      <td>6451</td>\n",
       "      <td>mcfarland cascade pole and lumber company</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21567</th>\n",
       "      <td>oregon school employees association local 6732</td>\n",
       "      <td>milwaukie</td>\n",
       "      <td>or</td>\n",
       "      <td>97267</td>\n",
       "      <td>0</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>1347</td>\n",
       "      <td>oregon school employees association local 6732</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>2276</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21569</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>2276</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21570</th>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>wa</td>\n",
       "      <td>98661</td>\n",
       "      <td>3606935841</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>4809</td>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>petermann northwest</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>98604</td>\n",
       "      <td>3606871479</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>e_e</td>\n",
       "      <td>1362</td>\n",
       "      <td>petermann northwest</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21572 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               entity       ent_city  \\\n",
       "0                                     pacific weather   port angeles   \n",
       "1                                      clp resources          tacoma   \n",
       "2                    graham construction  management         seattle   \n",
       "3                           ongaro burtt  louderback          tacoma   \n",
       "4          mcfarland cascade pole and lumber company          tacoma   \n",
       "...                                               ...            ...   \n",
       "21567  oregon school employees association local 6732      milwaukie   \n",
       "21568                                  first student     lake oswego   \n",
       "21569                                  first student     lake oswego   \n",
       "21570                              teamsters local 58      vancouver   \n",
       "21571                            petermann northwest   battle ground   \n",
       "\n",
       "      ent_state  ent_postcode  ent_phone_number    charge_city charge_state  \\\n",
       "0            wa         98362                 0   port angeles           wa   \n",
       "1            wa         98402                 0         tacoma           wa   \n",
       "2            wa         98115                 0        seattle           wa   \n",
       "3            wa         98402                 0         tacoma           wa   \n",
       "4            wa         98421                 0         tacoma           wa   \n",
       "...         ...           ...               ...            ...          ...   \n",
       "21567        or         97267                 0    lake oswego           or   \n",
       "21568        or         97035        5035342332    lake oswego           or   \n",
       "21569        or         97035        5035342332    lake oswego           or   \n",
       "21570        wa         98661        3606935841  battle ground           wa   \n",
       "21571        wa         98604        3606871479  battle ground           wa   \n",
       "\n",
       "       region   region_city  region_state  \\\n",
       "0           3       buffalo      new york   \n",
       "1           3       buffalo      new york   \n",
       "2           3       buffalo      new york   \n",
       "3           4  philadelphia  pennsylvania   \n",
       "4           4  philadelphia  pennsylvania   \n",
       "...       ...           ...           ...   \n",
       "21567      19       seattle    washington   \n",
       "21568      19       seattle    washington   \n",
       "21569      19       seattle    washington   \n",
       "21570      19       seattle    washington   \n",
       "21571      19       seattle    washington   \n",
       "\n",
       "                                               case_name   case_number  \\\n",
       "0                                     \"pacific weather \"  03-ca-027869   \n",
       "1      \"clp resources and controlled environmental st...  03-ca-122609   \n",
       "2                    \"graham construction & management \"  03-ca-143167   \n",
       "3      \"true blue  f/k/a labor ready  and its wholly ...  04-ca-075160   \n",
       "4           \"mcfarland cascade pole and lumber company \"  04-rc-067350   \n",
       "...                                                  ...           ...   \n",
       "21567                                   \"first student \"  36-ud-000376   \n",
       "21568                                   \"first student \"  36-ud-000376   \n",
       "21569                                   \"first student \"  36-ud-000376   \n",
       "21570                             \"petermann northwest \"  36-ud-000377   \n",
       "21571                             \"petermann northwest \"  36-ud-000377   \n",
       "\n",
       "         role  cluster                               standardized_name  \\\n",
       "0      cdp_re     6911                                 pacific weather   \n",
       "1      cdp_re     5751                                  clp resources    \n",
       "2      cdp_re     6627                graham construction  management    \n",
       "3      cdp_re     9523                       ongaro burtt  louderback    \n",
       "4         e_e     6451      mcfarland cascade pole and lumber company    \n",
       "...       ...      ...                                             ...   \n",
       "21567    ip_u     1347  oregon school employees association local 6732   \n",
       "21568     e_e     2276                                  first student    \n",
       "21569     e_e     2276                                  first student    \n",
       "21570    ip_u     4809                              teamsters local 58   \n",
       "21571     e_e     1362                            petermann northwest    \n",
       "\n",
       "       similarity_score  \n",
       "0                 100.0  \n",
       "1                 100.0  \n",
       "2                 100.0  \n",
       "3                 100.0  \n",
       "4                 100.0  \n",
       "...                 ...  \n",
       "21567             100.0  \n",
       "21568             100.0  \n",
       "21569             100.0  \n",
       "21570             100.0  \n",
       "21571             100.0  \n",
       "\n",
       "[21572 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee3c26",
   "metadata": {},
   "source": [
    "## tsne_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3a97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_tsne_kmeans(df, text_columns, numeric_columns, categorical_columns, target_column, n_clusters, max_features, n_components, threshold=90):\n",
    "    \"\"\"\n",
    "    Standardize names in the target column using t-SNE and K-Means clustering.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # vectorize using tfidf \n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df_copy[text_columns].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df_copy[numeric_columns])\n",
    "\n",
    "    # apply one-hot encoding for categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df_copy[categorical_columns])\n",
    "\n",
    "    # combine all features\n",
    "    processed_features = hstack([text_features, numeric_features, categorical_features])\n",
    "\n",
    "    # apply t-SNE for dimension reduction\n",
    "    tsne = TSNE(n_components=n_components, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(processed_features.toarray())\n",
    "\n",
    "    # use kmeans clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(tsne_features)\n",
    "\n",
    "    # assign the cluster labels to the data\n",
    "    df_copy['cluster'] = clusters\n",
    "\n",
    "    # find the most common name in each cluster and add it to the standardized_names dict\n",
    "    standardized_names = {}\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_data = df_copy[df_copy['cluster'] == cluster_id][target_column]\n",
    "        most_common_name = cluster_data.mode().iloc[0] if not cluster_data.mode().empty else \"Unknown\"\n",
    "        standardized_names[cluster_id] = most_common_name\n",
    "\n",
    "    # standardize name for each of the entities using the most common name detected\n",
    "    df_copy['standardized_name'] = df_copy['cluster'].map(standardized_names)\n",
    "\n",
    "    # eval using diff eval metrics\n",
    "    silhouette_avg = silhouette_score(tsne_features, clusters)\n",
    "    db_index = davies_bouldin_score(tsne_features, clusters)\n",
    "    ch_index = calinski_harabasz_score(tsne_features, clusters)\n",
    "\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "    print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "    print(f\"Calinski-Harabasz Index: {ch_index}\")\n",
    "\n",
    "    # evaluate similarity to see if the standardized name col is within 90% of similarity of the entity col \n",
    "    df_copy['similarity_score'] = df_copy.apply(lambda row: fuzz.token_sort_ratio(row[target_column], row['standardized_name']), axis=1)\n",
    "    matches = df_copy[df_copy['similarity_score'] >= threshold]\n",
    "    match_count = matches.shape[0]\n",
    "    pct_of_similarity = match_count / len(df_copy)\n",
    "\n",
    "    print(f\"Percentage of similarity: {pct_of_similarity}\")\n",
    "\n",
    "    return df_copy, silhouette_avg, db_index, ch_index, pct_of_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7b5a141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region']\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']\n",
    "text_columns = ['case_name']  \n",
    "target_column = 'entity'\n",
    "n_clusters = len(unique_entities)\n",
    "max_features = 1000\n",
    "n_components = 2\n",
    "\n",
    "tsne_kmeans_df, tsne_kmeans_silhouette, tsne_kmeans_db_index, tsne_kmeans_ch_index, tsne_kmeans_pct_of_similarity = unsupervised_tsne_kmeans(main_df, text_columns, numeric_columns, categorical_columns, target_column, n_clusters, max_features, n_components, threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56226b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>ent_city</th>\n",
       "      <th>ent_state</th>\n",
       "      <th>ent_postcode</th>\n",
       "      <th>ent_phone_number</th>\n",
       "      <th>charge_city</th>\n",
       "      <th>charge_state</th>\n",
       "      <th>region</th>\n",
       "      <th>region_city</th>\n",
       "      <th>region_state</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_number</th>\n",
       "      <th>role</th>\n",
       "      <th>cluster</th>\n",
       "      <th>standardized_name</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pacific weather</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>98362</td>\n",
       "      <td>0</td>\n",
       "      <td>port angeles</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"pacific weather \"</td>\n",
       "      <td>03-ca-027869</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>193</td>\n",
       "      <td>ziply fiber</td>\n",
       "      <td>30.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clp resources</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"clp resources and controlled environmental st...</td>\n",
       "      <td>03-ca-122609</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>193</td>\n",
       "      <td>ziply fiber</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graham construction  management</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>98115</td>\n",
       "      <td>0</td>\n",
       "      <td>seattle</td>\n",
       "      <td>wa</td>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>new york</td>\n",
       "      <td>\"graham construction &amp; management \"</td>\n",
       "      <td>03-ca-143167</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>193</td>\n",
       "      <td>ziply fiber</td>\n",
       "      <td>14.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ongaro burtt  louderback</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98402</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"true blue  f/k/a labor ready  and its wholly ...</td>\n",
       "      <td>04-ca-075160</td>\n",
       "      <td>cdp_re</td>\n",
       "      <td>193</td>\n",
       "      <td>ziply fiber</td>\n",
       "      <td>23.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcfarland cascade pole and lumber company</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>98421</td>\n",
       "      <td>0</td>\n",
       "      <td>tacoma</td>\n",
       "      <td>wa</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>\"mcfarland cascade pole and lumber company \"</td>\n",
       "      <td>04-rc-067350</td>\n",
       "      <td>e_e</td>\n",
       "      <td>193</td>\n",
       "      <td>ziply fiber</td>\n",
       "      <td>23.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21567</th>\n",
       "      <td>oregon school employees association local 6732</td>\n",
       "      <td>milwaukie</td>\n",
       "      <td>or</td>\n",
       "      <td>97267</td>\n",
       "      <td>0</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>3045</td>\n",
       "      <td>oregon school employees association aft local</td>\n",
       "      <td>92.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>1095</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21569</th>\n",
       "      <td>first student</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>97035</td>\n",
       "      <td>5035342332</td>\n",
       "      <td>lake oswego</td>\n",
       "      <td>or</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"first student \"</td>\n",
       "      <td>36-ud-000376</td>\n",
       "      <td>e_e</td>\n",
       "      <td>1095</td>\n",
       "      <td>first student</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21570</th>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>wa</td>\n",
       "      <td>98661</td>\n",
       "      <td>3606935841</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>ip_u</td>\n",
       "      <td>1955</td>\n",
       "      <td>teamsters local 58</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21571</th>\n",
       "      <td>petermann northwest</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>98604</td>\n",
       "      <td>3606871479</td>\n",
       "      <td>battle ground</td>\n",
       "      <td>wa</td>\n",
       "      <td>19</td>\n",
       "      <td>seattle</td>\n",
       "      <td>washington</td>\n",
       "      <td>\"petermann northwest \"</td>\n",
       "      <td>36-ud-000377</td>\n",
       "      <td>e_e</td>\n",
       "      <td>1241</td>\n",
       "      <td>sunrise dental</td>\n",
       "      <td>24.242424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21572 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               entity       ent_city  \\\n",
       "0                                     pacific weather   port angeles   \n",
       "1                                      clp resources          tacoma   \n",
       "2                    graham construction  management         seattle   \n",
       "3                           ongaro burtt  louderback          tacoma   \n",
       "4          mcfarland cascade pole and lumber company          tacoma   \n",
       "...                                               ...            ...   \n",
       "21567  oregon school employees association local 6732      milwaukie   \n",
       "21568                                  first student     lake oswego   \n",
       "21569                                  first student     lake oswego   \n",
       "21570                              teamsters local 58      vancouver   \n",
       "21571                            petermann northwest   battle ground   \n",
       "\n",
       "      ent_state  ent_postcode  ent_phone_number    charge_city charge_state  \\\n",
       "0            wa         98362                 0   port angeles           wa   \n",
       "1            wa         98402                 0         tacoma           wa   \n",
       "2            wa         98115                 0        seattle           wa   \n",
       "3            wa         98402                 0         tacoma           wa   \n",
       "4            wa         98421                 0         tacoma           wa   \n",
       "...         ...           ...               ...            ...          ...   \n",
       "21567        or         97267                 0    lake oswego           or   \n",
       "21568        or         97035        5035342332    lake oswego           or   \n",
       "21569        or         97035        5035342332    lake oswego           or   \n",
       "21570        wa         98661        3606935841  battle ground           wa   \n",
       "21571        wa         98604        3606871479  battle ground           wa   \n",
       "\n",
       "       region   region_city  region_state  \\\n",
       "0           3       buffalo      new york   \n",
       "1           3       buffalo      new york   \n",
       "2           3       buffalo      new york   \n",
       "3           4  philadelphia  pennsylvania   \n",
       "4           4  philadelphia  pennsylvania   \n",
       "...       ...           ...           ...   \n",
       "21567      19       seattle    washington   \n",
       "21568      19       seattle    washington   \n",
       "21569      19       seattle    washington   \n",
       "21570      19       seattle    washington   \n",
       "21571      19       seattle    washington   \n",
       "\n",
       "                                               case_name   case_number  \\\n",
       "0                                     \"pacific weather \"  03-ca-027869   \n",
       "1      \"clp resources and controlled environmental st...  03-ca-122609   \n",
       "2                    \"graham construction & management \"  03-ca-143167   \n",
       "3      \"true blue  f/k/a labor ready  and its wholly ...  04-ca-075160   \n",
       "4           \"mcfarland cascade pole and lumber company \"  04-rc-067350   \n",
       "...                                                  ...           ...   \n",
       "21567                                   \"first student \"  36-ud-000376   \n",
       "21568                                   \"first student \"  36-ud-000376   \n",
       "21569                                   \"first student \"  36-ud-000376   \n",
       "21570                             \"petermann northwest \"  36-ud-000377   \n",
       "21571                             \"petermann northwest \"  36-ud-000377   \n",
       "\n",
       "         role  cluster                              standardized_name  \\\n",
       "0      cdp_re      193                                    ziply fiber   \n",
       "1      cdp_re      193                                    ziply fiber   \n",
       "2      cdp_re      193                                    ziply fiber   \n",
       "3      cdp_re      193                                    ziply fiber   \n",
       "4         e_e      193                                    ziply fiber   \n",
       "...       ...      ...                                            ...   \n",
       "21567    ip_u     3045  oregon school employees association aft local   \n",
       "21568     e_e     1095                                 first student    \n",
       "21569     e_e     1095                                 first student    \n",
       "21570    ip_u     1955                             teamsters local 58   \n",
       "21571     e_e     1241                                 sunrise dental   \n",
       "\n",
       "       similarity_score  \n",
       "0             30.769231  \n",
       "1             16.666667  \n",
       "2             14.634146  \n",
       "3             23.529412  \n",
       "4             23.076923  \n",
       "...                 ...  \n",
       "21567         92.307692  \n",
       "21568        100.000000  \n",
       "21569        100.000000  \n",
       "21570        100.000000  \n",
       "21571         24.242424  \n",
       "\n",
       "[21572 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_kmeans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654c874",
   "metadata": {},
   "source": [
    "## tsne_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "808e818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_tsne_agglomerative(df, text_columns, numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold, threshold=90):\n",
    "    \"\"\"\n",
    "    Standardize names in the target column using t-SNE and agglomerative clustering.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy of df\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # vectorize text columns using tfidf\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    text_features = vectorizer.fit_transform(df_copy[text_columns].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "    # standardize numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    numeric_features = scaler.fit_transform(df_copy[numeric_columns])\n",
    "\n",
    "    # apply one hot encoding for categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "    categorical_features = encoder.fit_transform(df_copy[categorical_columns])\n",
    "\n",
    "    # combine all features\n",
    "    processed_features = hstack([text_features, numeric_features, categorical_features])\n",
    "\n",
    "    # apply tsne for dimensionality reduction\n",
    "    tsne = TSNE(n_components=n_components, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(processed_features.toarray())\n",
    "\n",
    "    # use agglomerative clustering\n",
    "    agglomerative = AgglomerativeClustering(distance_threshold=distance_threshold, n_clusters=None)\n",
    "    clusters = agglomerative.fit_predict(tsne_features)\n",
    "\n",
    "    # assign the cluster labels to the data\n",
    "    df_copy['cluster'] = clusters\n",
    "\n",
    "    # find the most common name in each cluster and add it to the standardized_names dict\n",
    "    standardized_names = {}\n",
    "    unique_clusters = df_copy['cluster'].unique()\n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_data = df_copy[df_copy['cluster'] == cluster_id][target_column]\n",
    "        most_common_name = cluster_data.mode().iloc[0] if not cluster_data.mode().empty else \"Unknown\"\n",
    "        standardized_names[cluster_id] = most_common_name\n",
    "\n",
    "    # standardize name for each of the entities using the most common name detected\n",
    "    df_copy['standardized_name'] = df_copy['cluster'].map(standardized_names)\n",
    "\n",
    "    # evaluate using diff metrics\n",
    "    silhouette_avg = silhouette_score(tsne_features, clusters)\n",
    "    db_index = davies_bouldin_score(tsne_features, clusters)\n",
    "    ch_index = calinski_harabasz_score(tsne_features, clusters)\n",
    "\n",
    "    print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "    print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "    print(f\"Calinski-Harabasz Index: {ch_index}\")\n",
    "\n",
    "    # evaluate similarity to see if the standardized name col is within 90% of similarity of the entity col \n",
    "    df_copy['similarity_score'] = df_copy.apply(lambda row: fuzz.token_sort_ratio(row[target_column], row['standardized_name']), axis=1)\n",
    "    matches = df_copy[df_copy['similarity_score'] >= threshold]\n",
    "    match_count = matches.shape[0]\n",
    "    pct_of_similarity = match_count / len(df_copy)\n",
    "\n",
    "    print(f\"Percentage of similarity: {pct_of_similarity}\")\n",
    "\n",
    "    return df_copy, silhouette_avg, db_index, ch_index, pct_of_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4a9e7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = ['ent_postcode', 'ent_phone_number', 'region']\n",
    "categorical_columns = ['ent_city', 'ent_state', 'charge_city', 'charge_state', 'region_city', 'region_state', 'role']\n",
    "text_columns = ['case_name']  \n",
    "target_column = 'entity'\n",
    "max_features = 1000\n",
    "n_components = 2\n",
    "distance_threshold = 0.1\n",
    "\n",
    "tsne_agg_df, tsne_agg_silhouette, tsne_agg_db_index, tsne_agg_ch_index, tsne_agg_pct_similarity = unsupervised_tsne_agglomerative(main_df, text_columns, numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold=distance_threshold, threshold=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e41a3f",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f260db",
   "metadata": {},
   "source": [
    "### sensitivity analysis for pca_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "697fa529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for n_components=100, max_features=100\n",
      "Silhouette Score: 0.6601953122654876\n",
      "Davies-Bouldin Index: 0.6050801783392146\n",
      "Calinski-Harabasz Index: 447.3146334139011\n",
      "Percentage of Similarity: 0.5581309104394585\n",
      "Running for n_components=100, max_features=1000\n",
      "Silhouette Score: 0.5935605538670321\n",
      "Davies-Bouldin Index: 0.4787256846475272\n",
      "Calinski-Harabasz Index: 1176.7296692520006\n",
      "Percentage of Similarity: 0.5485814945299462\n",
      "Running for n_components=100, max_features=10000\n",
      "Silhouette Score: 0.6073191077197236\n",
      "Davies-Bouldin Index: 0.38712617441215924\n",
      "Calinski-Harabasz Index: 2247.577788863425\n",
      "Percentage of Similarity: 0.5470053773409976\n",
      "Running for n_components=164, max_features=100\n",
      "Silhouette Score: 0.6522835727565083\n",
      "Davies-Bouldin Index: 0.6987583296387304\n",
      "Calinski-Harabasz Index: 261.3702109080762\n",
      "Percentage of Similarity: 0.5696272946412015\n",
      "Running for n_components=164, max_features=1000\n",
      "Silhouette Score: 0.5666709781294453\n",
      "Davies-Bouldin Index: 0.6035252665342752\n",
      "Calinski-Harabasz Index: 483.22776628386447\n",
      "Percentage of Similarity: 0.566614129427035\n",
      "Running for n_components=164, max_features=10000\n",
      "Silhouette Score: 0.5854715316111226\n",
      "Davies-Bouldin Index: 0.5054239885340506\n",
      "Calinski-Harabasz Index: 797.0920519352186\n",
      "Percentage of Similarity: 0.5570647135175227\n",
      "Running for n_components=200, max_features=100\n",
      "Silhouette Score: 0.6462080194023107\n",
      "Davies-Bouldin Index: 0.7399526728773794\n",
      "Calinski-Harabasz Index: 222.5935185306584\n",
      "Percentage of Similarity: 0.571713332097163\n",
      "Running for n_components=200, max_features=1000\n",
      "Silhouette Score: 0.5579141516439594\n",
      "Davies-Bouldin Index: 0.6586337854582083\n",
      "Calinski-Harabasz Index: 359.4237825719867\n",
      "Percentage of Similarity: 0.574633784535509\n",
      "Running for n_components=200, max_features=10000\n",
      "Silhouette Score: 0.5747388885793172\n",
      "Davies-Bouldin Index: 0.5451195547376402\n",
      "Calinski-Harabasz Index: 572.459641485961\n",
      "Percentage of Similarity: 0.5649452994622659\n",
      "   n_components  max_features  silhouette_avg  db_index     ch_index  \\\n",
      "0           100           100        0.660195  0.605080   447.314633   \n",
      "1           100          1000        0.593561  0.478726  1176.729669   \n",
      "2           100         10000        0.607319  0.387126  2247.577789   \n",
      "3           164           100        0.652284  0.698758   261.370211   \n",
      "4           164          1000        0.566671  0.603525   483.227766   \n",
      "5           164         10000        0.585472  0.505424   797.092052   \n",
      "6           200           100        0.646208  0.739953   222.593519   \n",
      "7           200          1000        0.557914  0.658634   359.423783   \n",
      "8           200         10000        0.574739  0.545120   572.459641   \n",
      "\n",
      "   pct_of_similarity  \n",
      "0           0.558131  \n",
      "1           0.548581  \n",
      "2           0.547005  \n",
      "3           0.569627  \n",
      "4           0.566614  \n",
      "5           0.557065  \n",
      "6           0.571713  \n",
      "7           0.574634  \n",
      "8           0.564945  \n"
     ]
    }
   ],
   "source": [
    "# specify num of components range, for our main models we use 164\n",
    "n_components_range = [100, 164, 200]\n",
    "\n",
    "# specify num of components range, for our main models we use 164\n",
    "max_features_range = [100, 1000, 10000]\n",
    "\n",
    "pca_kmeans_results = []\n",
    "\n",
    "# loop across specified parameters\n",
    "for n_components in n_components_range:\n",
    "    for max_features in max_features_range:\n",
    "        print(f\"Running for n_components={n_components}, max_features={max_features}\")\n",
    "        try:\n",
    "            # run the unsupervised_pca_kmeans function\n",
    "            pca_kmeans_df, pca_kmeans_silhouette, pca_kmeans_db_index, pca_kmeans_ch_index, pca_kmeans_pca_similarity = unsupervised_pca_kmeans(\n",
    "                main_df,text_columns, numeric_columns, categorical_columns, target_column, n_clusters=3926, max_features=max_features, n_components=n_components, threshold=90)\n",
    "            \n",
    "            # store results\n",
    "            pca_kmeans_results.append({\n",
    "                'n_components': n_components,\n",
    "                'max_features': max_features,\n",
    "                'silhouette_avg': pca_kmeans_silhouette,\n",
    "                'db_index': pca_kmeans_db_index,\n",
    "                'ch_index': pca_kmeans_ch_index,\n",
    "                'pct_of_similarity': pca_kmeans_pca_similarity})\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for n_components={n_components}, max_features={max_features}: {e}\")\n",
    "\n",
    "pca_kmeans_results_df = pd.DataFrame(pca_kmeans_results)\n",
    "\n",
    "print(pca_kmeans_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227af9b",
   "metadata": {},
   "source": [
    "### sensitivity analysis for pca_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9653c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for n_components=100, max_features=100\n",
      "Silhouette Score: 0.7330897011247874\n",
      "Davies-Bouldin Index: 0.04433899171519896\n",
      "Calinski-Harabasz Index: 256816.54931957743\n",
      "Percentage of similarity: 0.7356295197478212\n",
      "Running for n_components=100, max_features=1000\n",
      "Silhouette Score: 0.6486352903084565\n",
      "Davies-Bouldin Index: 0.10858176608089357\n",
      "Calinski-Harabasz Index: 61145.452011616544\n",
      "Percentage of similarity: 0.7984424253662155\n",
      "Running for n_components=100, max_features=10000\n",
      "Silhouette Score: 0.6449110737289058\n",
      "Davies-Bouldin Index: 0.13509365050895164\n",
      "Calinski-Harabasz Index: 53602.219050636864\n",
      "Percentage of similarity: 0.7745688855924346\n",
      "Running for n_components=164, max_features=100\n",
      "Silhouette Score: 0.7312064486652984\n",
      "Davies-Bouldin Index: 0.0320956870458932\n",
      "Calinski-Harabasz Index: 397983.68367622345\n",
      "Percentage of similarity: 0.7444835898386798\n",
      "Running for n_components=164, max_features=1000\n",
      "Silhouette Score: 0.6453621189734835\n",
      "Davies-Bouldin Index: 0.06596890418723662\n",
      "Calinski-Harabasz Index: 100612.85640492055\n",
      "Percentage of similarity: 0.8355738920823289\n",
      "Running for n_components=164, max_features=10000\n",
      "Silhouette Score: 0.6425879872254455\n",
      "Davies-Bouldin Index: 0.08513966421683877\n",
      "Calinski-Harabasz Index: 74116.28864907178\n",
      "Percentage of similarity: 0.821342480993881\n",
      "Running for n_components=200, max_features=100\n",
      "Silhouette Score: 0.7308787059496642\n",
      "Davies-Bouldin Index: 0.0325122126749322\n",
      "Calinski-Harabasz Index: 448775.77482008375\n",
      "Percentage of similarity: 0.7461060634155386\n",
      "Running for n_components=200, max_features=1000\n",
      "Silhouette Score: 0.6470545196598104\n",
      "Davies-Bouldin Index: 0.05014342628583593\n",
      "Calinski-Harabasz Index: 149516.9228136717\n",
      "Percentage of similarity: 0.8477656221027258\n",
      "Running for n_components=200, max_features=10000\n",
      "Silhouette Score: 0.6402304016331007\n",
      "Davies-Bouldin Index: 0.07376660442494744\n",
      "Calinski-Harabasz Index: 86134.53876322585\n",
      "Percentage of similarity: 0.8350639718153161\n",
      "   n_components  max_features  silhouette_avg  db_index       ch_index  \\\n",
      "0           100           100        0.733090  0.044339  256816.549320   \n",
      "1           100          1000        0.648635  0.108582   61145.452012   \n",
      "2           100         10000        0.644911  0.135094   53602.219051   \n",
      "3           164           100        0.731206  0.032096  397983.683676   \n",
      "4           164          1000        0.645362  0.065969  100612.856405   \n",
      "5           164         10000        0.642588  0.085140   74116.288649   \n",
      "6           200           100        0.730879  0.032512  448775.774820   \n",
      "7           200          1000        0.647055  0.050143  149516.922814   \n",
      "8           200         10000        0.640230  0.073767   86134.538763   \n",
      "\n",
      "   pct_of_similarity  \n",
      "0           0.735630  \n",
      "1           0.798442  \n",
      "2           0.774569  \n",
      "3           0.744484  \n",
      "4           0.835574  \n",
      "5           0.821342  \n",
      "6           0.746106  \n",
      "7           0.847766  \n",
      "8           0.835064  \n"
     ]
    }
   ],
   "source": [
    "# specify num of components range, for our main models we use 164\n",
    "n_components_range = [100, 164, 200]\n",
    "\n",
    "# specify num of components range, for our main models we use 164\n",
    "max_features_range = [100, 1000, 10000]\n",
    "\n",
    "pca_agglomerative_results = []\n",
    "\n",
    "# loop across specified parameters\n",
    "for n_components in n_components_range:\n",
    "    for max_features in max_features_range:\n",
    "        print(f\"Running for n_components={n_components}, max_features={max_features}\")\n",
    "        try:\n",
    "            # run the unsupervised_pca_agglomerative function\n",
    "            pca_agg_df, pca_agg_silhouette, pca_agg_db_index, pca_agg_ch_index, pca_agg_similarity = unsupervised_pca_agglomerative(main_df, text_columns, \n",
    "            numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold=0.1, threshold=90)\n",
    "\n",
    "            \n",
    "            # store the results\n",
    "            pca_agglomerative_results.append({\n",
    "                'n_components': n_components,\n",
    "                'max_features': max_features,\n",
    "                'silhouette_avg': pca_agg_silhouette,\n",
    "                'db_index': pca_agg_db_index,\n",
    "                'ch_index': pca_agg_ch_index,\n",
    "                'pct_of_similarity': pca_agg_similarity})\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for n_components={n_components}, max_features={max_features}: {e}\")\n",
    "\n",
    "pca_agglomerative_results_df = pd.DataFrame(pca_agglomerative_results)\n",
    "\n",
    "print(pca_agglomerative_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb38eb",
   "metadata": {},
   "source": [
    "### sensitivity analysis for tsne_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c27ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for n_components=1, max_features=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snazaral/.local/lib/python3.9/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (3838) found smaller than n_clusters (3926). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.7243363261222839\n",
      "Davies-Bouldin Index: 0.22749304397561393\n",
      "Calinski-Harabasz Index: 811837696.3350518\n",
      "Percentage of similarity: 0.5322640459855368\n",
      "Running for n_components=1, max_features=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snazaral/.local/lib/python3.9/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (3811) found smaller than n_clusters (3926). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6913195252418518\n",
      "Davies-Bouldin Index: 0.27575929598796645\n",
      "Calinski-Harabasz Index: 620715452.2100738\n",
      "Percentage of similarity: 0.5504821064342666\n",
      "Running for n_components=1, max_features=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snazaral/.local/lib/python3.9/site-packages/sklearn/base.py:1473: ConvergenceWarning: Number of distinct clusters (3888) found smaller than n_clusters (3926). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6683393716812134\n",
      "Davies-Bouldin Index: 0.2779117399270478\n",
      "Calinski-Harabasz Index: 417435071.25588703\n",
      "Percentage of similarity: 0.5439458557389208\n",
      "Running for n_components=2, max_features=100\n",
      "Silhouette Score: 0.7784396409988403\n",
      "Davies-Bouldin Index: 0.2741859403756169\n",
      "Calinski-Harabasz Index: 444908.5880011939\n",
      "Percentage of similarity: 0.5853884665306879\n",
      "Running for n_components=2, max_features=1000\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "Running for n_components=2, max_features=10000\n",
      "Silhouette Score: 0.7510783076286316\n",
      "Davies-Bouldin Index: 0.3155468187841202\n",
      "Calinski-Harabasz Index: 241054.3597761237\n",
      "Percentage of similarity: 0.617698868904135\n",
      "   n_components  max_features  silhouette_avg  db_index      ch_index  \\\n",
      "0             1           100        0.724336  0.227493  8.118377e+08   \n",
      "1             1          1000        0.691320  0.275759  6.207155e+08   \n",
      "2             1         10000        0.668339  0.277912  4.174351e+08   \n",
      "3             2           100        0.778440  0.274186  4.449086e+05   \n",
      "4             2          1000        0.764253  0.302830  3.163157e+05   \n",
      "5             2         10000        0.751078  0.315547  2.410544e+05   \n",
      "\n",
      "   pct_of_similarity  \n",
      "0           0.532264  \n",
      "1           0.550482  \n",
      "2           0.543946  \n",
      "3           0.585388  \n",
      "4           0.616076  \n",
      "5           0.617699  \n"
     ]
    }
   ],
   "source": [
    "# specify num of components range, for our main models we use 206\n",
    "n_components_range = [1, 2]\n",
    "\n",
    "# specify num of components range, for our main models we use 206\n",
    "max_features_range = [100, 1000, 10000]\n",
    "\n",
    "tsne_kmeans_results = []\n",
    "\n",
    "# loop across specified parameters\n",
    "for n_components in n_components_range:\n",
    "    for max_features in max_features_range:\n",
    "        print(f\"Running for n_components={n_components}, max_features={max_features}\")\n",
    "        try:\n",
    "            # run the unsupervised_tsne_kmeans function\n",
    "            tsne_kmeans_df, tsne_kmeans_silhouette, tsne_kmeans_db_index, tsne_kmeans_ch_index, tsne_kmeans_pca_similarity = unsupervised_tsne_kmeans(\n",
    "                main_df, text_columns, numeric_columns, categorical_columns, target_column, 3926, max_features, n_components)\n",
    "            \n",
    "            # store the results\n",
    "            tsne_kmeans_results.append({\n",
    "                'n_components': n_components,\n",
    "                'max_features': max_features,\n",
    "                'silhouette_avg': tsne_kmeans_silhouette,\n",
    "                'db_index': tsne_kmeans_db_index,\n",
    "                'ch_index': tsne_kmeans_ch_index,\n",
    "                'pct_of_similarity': tsne_kmeans_pca_similarity})\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for n_components={n_components}, max_features={max_features}: {e}\")\n",
    "\n",
    "tsne_kmeans_results_df = pd.DataFrame(tsne_kmeans_results)\n",
    "\n",
    "print(tsne_kmeans_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aca777",
   "metadata": {},
   "source": [
    "### sensitivity analysis for tsne_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9985d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for n_components=1, max_features=100\n",
      "Silhouette Score: 0.7656919360160828\n",
      "Davies-Bouldin Index: 0.2916750227711943\n",
      "Calinski-Harabasz Index: 265067170.3892358\n",
      "Percentage of similarity: 0.4472464305581309\n",
      "Running for n_components=1, max_features=1000\n",
      "Silhouette Score: 0.7427453994750977\n",
      "Davies-Bouldin Index: 0.3056101142225912\n",
      "Calinski-Harabasz Index: 242352385.43042535\n",
      "Percentage of similarity: 0.4660207676617838\n",
      "Running for n_components=1, max_features=10000\n",
      "Silhouette Score: 0.7195737361907959\n",
      "Davies-Bouldin Index: 0.3225651449088818\n",
      "Calinski-Harabasz Index: 190851871.8636864\n",
      "Percentage of similarity: 0.47019284257370664\n",
      "Running for n_components=2, max_features=100\n",
      "Silhouette Score: 0.7594237327575684\n",
      "Davies-Bouldin Index: 0.06268721051946177\n",
      "Calinski-Harabasz Index: 59135480.42114508\n",
      "Percentage of similarity: 0.7490265158538847\n",
      "Running for n_components=2, max_features=1000\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "Running for n_components=2, max_features=10000\n",
      "Silhouette Score: 0.7284296751022339\n",
      "Davies-Bouldin Index: 0.06793887277690273\n",
      "Calinski-Harabasz Index: 41321428.441967875\n",
      "Percentage of similarity: 0.8124884109030225\n",
      "   n_components  max_features  silhouette_avg  db_index      ch_index  \\\n",
      "0             1           100        0.765692  0.291675  2.650672e+08   \n",
      "1             1          1000        0.742745  0.305610  2.423524e+08   \n",
      "2             1         10000        0.719574  0.322565  1.908519e+08   \n",
      "3             2           100        0.759424  0.062687  5.913548e+07   \n",
      "4             2          1000        0.753645  0.064171  5.037844e+07   \n",
      "5             2         10000        0.728430  0.067939  4.132143e+07   \n",
      "\n",
      "   pct_of_similarity  \n",
      "0           0.447246  \n",
      "1           0.466021  \n",
      "2           0.470193  \n",
      "3           0.749027  \n",
      "4           0.798396  \n",
      "5           0.812488  \n"
     ]
    }
   ],
   "source": [
    "# specify num of components range, for our main models we use 206\n",
    "n_components_range = [1, 2]\n",
    "\n",
    "# specify num of components range, for our main models we use 206\n",
    "max_features_range = [100, 1000, 10000]\n",
    "\n",
    "tsne_agglomerative_results = []\n",
    "\n",
    "# loop across specified parameters\n",
    "for n_components in n_components_range:\n",
    "    for max_features in max_features_range:\n",
    "        print(f\"Running for n_components={n_components}, max_features={max_features}\")\n",
    "        try:\n",
    "            # run the unsupervised_tsne_agglomerative function\n",
    "            tsne_agglomerative_df, tsne_agglomerative_silhouette, tsne_agglomerative_db_index, tsne_agglomerative_ch_index, tsne_agglomerative_similarity = unsupervised_tsne_agglomerative(main_df, text_columns, numeric_columns, categorical_columns, target_column, max_features, n_components, distance_threshold=0.1, threshold=90)\n",
    "\n",
    "            \n",
    "            # store the results\n",
    "            tsne_agglomerative_results.append({\n",
    "                'n_components': n_components,\n",
    "                'max_features': max_features,\n",
    "                'silhouette_avg': tsne_agglomerative_silhouette,\n",
    "                'db_index': tsne_agglomerative_db_index,\n",
    "                'ch_index': tsne_agglomerative_ch_index,\n",
    "                'pct_of_similarity': tsne_agglomerative_similarity})\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for n_components={n_components}, max_features={max_features}: {e}\")\n",
    "\n",
    "tsne_agglomerative_results_df = pd.DataFrame(tsne_agglomerative_results)\n",
    "\n",
    "print(tsne_agglomerative_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5223e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_kmeans_results_df.to_csv(\"pca_kmeans_results_df.csv\", index=False)\n",
    "pca_agglomerative_results_df.to_csv(\"pca_agglomerative_results_df.csv\", index=False)\n",
    "tsne_kmeans_results_df.to_csv(\"tsne_kmeans_results_df.csv\", index=False)\n",
    "tsne_agglomerative_results_df.to_csv(\"tsne_agglomerative_results_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1ef36",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f38485",
   "metadata": {},
   "source": [
    "### cross validation for pca_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f47aa196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation iteration 1\n",
      "Silhouette Score: 0.569629629719997\n",
      "Davies-Bouldin Index: 0.5974334729428996\n",
      "Calinski-Harabasz Index: 483.8158914443596\n",
      "Percentage of Similarity: 0.5661505655479325\n",
      "Running cross-validation iteration 2\n",
      "Silhouette Score: 0.5694038892040079\n",
      "Davies-Bouldin Index: 0.5972132892257324\n",
      "Calinski-Harabasz Index: 488.2107308687488\n",
      "Percentage of Similarity: 0.5669849805303171\n",
      "Running cross-validation iteration 3\n",
      "Silhouette Score: 0.5597895376283445\n",
      "Davies-Bouldin Index: 0.60962512845157\n",
      "Calinski-Harabasz Index: 481.6601286376001\n",
      "Percentage of Similarity: 0.5680048210643427\n",
      "Running cross-validation iteration 4\n",
      "Silhouette Score: 0.5728624127575171\n",
      "Davies-Bouldin Index: 0.6064417218815631\n",
      "Calinski-Harabasz Index: 484.7310712519797\n",
      "Percentage of Similarity: 0.5671240496940478\n",
      "Running cross-validation iteration 5\n",
      "Silhouette Score: 0.5705360491082948\n",
      "Davies-Bouldin Index: 0.603421264300795\n",
      "Calinski-Harabasz Index: 481.47099724015885\n",
      "Percentage of Similarity: 0.5661969219358428\n",
      "   Silhouette Score  Davies-Bouldin Index  Calinski-Harabasz Index  \\\n",
      "0          0.569630              0.597433               483.815891   \n",
      "1          0.569404              0.597213               488.210731   \n",
      "2          0.559790              0.609625               481.660129   \n",
      "3          0.572862              0.606442               484.731071   \n",
      "4          0.570536              0.603421               481.470997   \n",
      "\n",
      "   Percentage of Similarity  \n",
      "0                  0.566151  \n",
      "1                  0.566985  \n",
      "2                  0.568005  \n",
      "3                  0.567124  \n",
      "4                  0.566197  \n"
     ]
    }
   ],
   "source": [
    "pca_kmeans_cv_df = pd.DataFrame(columns=['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index', 'Percentage of Similarity'])\n",
    "\n",
    "# run the function 5 times for cross-validation\n",
    "for i in range(5):\n",
    "    print(f\"Running cross-validation iteration {i+1}\")\n",
    "    \n",
    "    # call the unsupervised_pca_kmeans function\n",
    "    pca_kmeans_df, pca_kmeans_silhouette, pca_kmeans_db_index, pca_kmeans_ch_index, pca_kmeans_similarity = unsupervised_pca_kmeans(\n",
    "                main_df,text_columns, numeric_columns, categorical_columns, target_column, n_clusters=3926, max_features=1000, n_components=164, threshold=90)\n",
    "    \n",
    "    # append the scores to the df\n",
    "    pca_kmeans_cv_df = pca_kmeans_cv_df.append({\n",
    "        'Silhouette Score': pca_kmeans_silhouette,\n",
    "        'Davies-Bouldin Index': pca_kmeans_db_index,\n",
    "        'Calinski-Harabasz Index': pca_kmeans_ch_index,\n",
    "        'Percentage of Similarity': pca_kmeans_similarity}, ignore_index=True)\n",
    "\n",
    "print(pca_kmeans_cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29d23c",
   "metadata": {},
   "source": [
    "### cross validation for pca_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31ed0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation iteration 1\n",
      "Silhouette Score: 0.6453638166598811\n",
      "Davies-Bouldin Index: 0.06756138430155577\n",
      "Calinski-Harabasz Index: 101470.58672569836\n",
      "Percentage of similarity: 0.8353421101427777\n",
      "Running cross-validation iteration 2\n",
      "Silhouette Score: 0.6447444349821437\n",
      "Davies-Bouldin Index: 0.06721271544571986\n",
      "Calinski-Harabasz Index: 98803.83466839336\n",
      "Percentage of similarity: 0.8344149823845726\n",
      "Running cross-validation iteration 3\n",
      "Silhouette Score: 0.6460453960986113\n",
      "Davies-Bouldin Index: 0.06501747157814121\n",
      "Calinski-Harabasz Index: 102996.19918704794\n",
      "Percentage of similarity: 0.8357593176339699\n",
      "Running cross-validation iteration 4\n",
      "Silhouette Score: 0.6449449000317361\n",
      "Davies-Bouldin Index: 0.06714219145791682\n",
      "Calinski-Harabasz Index: 101391.19703897175\n",
      "Percentage of similarity: 0.8354348229185982\n",
      "Running cross-validation iteration 5\n",
      "Silhouette Score: 0.6454665451749377\n",
      "Davies-Bouldin Index: 0.06673031433850919\n",
      "Calinski-Harabasz Index: 100029.24868106093\n",
      "Percentage of similarity: 0.8353884665306879\n",
      "   Silhouette Score  Davies-Bouldin Index  Calinski-Harabasz Index  \\\n",
      "0          0.645364              0.067561            101470.586726   \n",
      "1          0.644744              0.067213             98803.834668   \n",
      "2          0.646045              0.065017            102996.199187   \n",
      "3          0.644945              0.067142            101391.197039   \n",
      "4          0.645467              0.066730            100029.248681   \n",
      "\n",
      "   Percentage of Similarity  \n",
      "0                  0.835342  \n",
      "1                  0.834415  \n",
      "2                  0.835759  \n",
      "3                  0.835435  \n",
      "4                  0.835388  \n"
     ]
    }
   ],
   "source": [
    "pca_agglomerative_cv_df = pd.DataFrame(columns=['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index', 'Percentage of Similarity'])\n",
    "\n",
    "# run the function 5 times for cross-validation\n",
    "for i in range(5):\n",
    "    print(f\"Running cross-validation iteration {i+1}\")\n",
    "    \n",
    "    try:\n",
    "        # call the unsupervised_pca_agglomerative function\n",
    "        pca_agglomerative_df, pca_agglomerative_silhouette, pca_agglomerative_db_index, pca_agglomerative_ch_index, pca_agglomerative_similarity = unsupervised_pca_agglomerative(main_df, text_columns, numeric_columns, categorical_columns, target_column, max_features=1000, n_components = 164, distance_threshold=0.1, threshold=90)\n",
    "        \n",
    "        # append the scores to the df\n",
    "        pca_agglomerative_cv_df = pca_agglomerative_cv_df.append({\n",
    "            'Silhouette Score': pca_agglomerative_silhouette,\n",
    "            'Davies-Bouldin Index': pca_agglomerative_db_index,\n",
    "            'Calinski-Harabasz Index': pca_agglomerative_ch_index,\n",
    "            'Percentage of Similarity': pca_agglomerative_similarity}, ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed for cross-validation iteration {i+1}: {e}\")\n",
    "\n",
    "print(pca_agglomerative_cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f7cdb",
   "metadata": {},
   "source": [
    "### cross validation for tsne_w_kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3358e4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation iteration 1\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "Running cross-validation iteration 2\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "Running cross-validation iteration 3\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "Running cross-validation iteration 4\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "Running cross-validation iteration 5\n",
      "Silhouette Score: 0.7642533183097839\n",
      "Davies-Bouldin Index: 0.30283005256912426\n",
      "Calinski-Harabasz Index: 316315.6731906529\n",
      "Percentage of similarity: 0.6160763953272761\n",
      "   Silhouette Score  Davies-Bouldin Index  Calinski-Harabasz Index  \\\n",
      "0          0.764253               0.30283            316315.673191   \n",
      "1          0.764253               0.30283            316315.673191   \n",
      "2          0.764253               0.30283            316315.673191   \n",
      "3          0.764253               0.30283            316315.673191   \n",
      "4          0.764253               0.30283            316315.673191   \n",
      "\n",
      "   Percentage of Similarity  \n",
      "0                  0.616076  \n",
      "1                  0.616076  \n",
      "2                  0.616076  \n",
      "3                  0.616076  \n",
      "4                  0.616076  \n"
     ]
    }
   ],
   "source": [
    "tsne_kmeans_cv_df = pd.DataFrame(columns=['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index', 'Percentage of Similarity'])\n",
    "\n",
    "# run the function 5 times for cross-validation\n",
    "for i in range(5):\n",
    "    print(f\"Running cross-validation iteration {i+1}\")\n",
    "    \n",
    "    try:\n",
    "        # call the unsupervised_tsne_kmeans function\n",
    "        tsne_kmeans_df, tsne_kmeans_silhouette, tsne_kmeans_db_index, tsne_kmeans_ch_index, tsne_kmeans_similarity = unsupervised_tsne_kmeans(\n",
    "            main_df, text_columns, numeric_columns, categorical_columns, target_column, n_clusters=3926, max_features=1000, n_components=2)\n",
    "        \n",
    "        # append the scores to the df\n",
    "        tsne_kmeans_cv_df = tsne_kmeans_cv_df.append({\n",
    "            'Silhouette Score': tsne_kmeans_silhouette,\n",
    "            'Davies-Bouldin Index': tsne_kmeans_db_index,\n",
    "            'Calinski-Harabasz Index': tsne_kmeans_ch_index,\n",
    "            'Percentage of Similarity': tsne_kmeans_similarity}, ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed for cross-validation iteration {i+1}: {e}\")\n",
    "\n",
    "print(tsne_kmeans_cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb43f5",
   "metadata": {},
   "source": [
    "### cross validation for tsne_w_agglomerative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "924ffe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross-validation iteration 1\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "Running cross-validation iteration 2\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "Running cross-validation iteration 3\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "Running cross-validation iteration 4\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "Running cross-validation iteration 5\n",
      "Silhouette Score: 0.7536448836326599\n",
      "Davies-Bouldin Index: 0.06417127259147974\n",
      "Calinski-Harabasz Index: 50378435.61918042\n",
      "Percentage of similarity: 0.7983960689783052\n",
      "   Silhouette Score  Davies-Bouldin Index  Calinski-Harabasz Index  \\\n",
      "0          0.753645              0.064171             5.037844e+07   \n",
      "1          0.753645              0.064171             5.037844e+07   \n",
      "2          0.753645              0.064171             5.037844e+07   \n",
      "3          0.753645              0.064171             5.037844e+07   \n",
      "4          0.753645              0.064171             5.037844e+07   \n",
      "\n",
      "   Percentage of Similarity  \n",
      "0                  0.798396  \n",
      "1                  0.798396  \n",
      "2                  0.798396  \n",
      "3                  0.798396  \n",
      "4                  0.798396  \n"
     ]
    }
   ],
   "source": [
    "tsne_agglomerative_cv_df = pd.DataFrame(columns=['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Index', 'Percentage of Similarity'])\n",
    "\n",
    "# run the function 5 times for cross-validation\n",
    "for i in range(5):\n",
    "    print(f\"Running cross-validation iteration {i+1}\")\n",
    "    \n",
    "    try:\n",
    "        # call the unsupervised_tsne_agglomerative function\n",
    "        tsne_agglomerative_df, tsne_agglomerative_silhouette, tsne_agglomerative_db_index, tsne_agglomerative_ch_index, tsne_agglomerative_similarity = unsupervised_tsne_agglomerative(main_df, text_columns, numeric_columns, categorical_columns, target_column, max_features=1000, n_components=2, distance_threshold=0.1, threshold=90)\n",
    "        \n",
    "        # append the scores to the df\n",
    "        tsne_agglomerative_cv_df = tsne_agglomerative_cv_df.append({\n",
    "            'Silhouette Score': tsne_agglomerative_silhouette,\n",
    "            'Davies-Bouldin Index': tsne_agglomerative_db_index,\n",
    "            'Calinski-Harabasz Index': tsne_agglomerative_ch_index,\n",
    "            'Percentage of Similarity': tsne_agglomerative_similarity}, ignore_index=True)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed for cross-validation iteration {i+1}: {e}\")\n",
    "\n",
    "print(tsne_agglomerative_cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16dee6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_kmeans_cv_df.to_csv(\"pca_kmeans_cv_df\", index = False)\n",
    "pca_agglomerative_cv_df.to_csv(\"pca_agglomerative_cv_df\", index = False)\n",
    "tsne_kmeans_cv_df.to_csv(\"tsne_kmeans_cv_df\", index = False)\n",
    "tsne_agglomerative_cv_df.to_csv(\"tsne_agglomerative_cv_df\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfaf04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
